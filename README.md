ğŸš€ MSME ONE â€“ AI Support Assistant

An intelligent multilingual chatbot system built using Python Flask, Ollama Local LLMs, React Frontend, and Whisper speech-to-text.
Supports multiple AI models (LLaMA / Phi / Mistral) and PDF-based training per model.

ğŸ“Œ Features
ğŸ§  AI Chat (Local Offline)

Uses Ollama to run LLMs locally

Supports:

llama3.2

phi3

mistral

Replies in Telugu, English, or auto-detects language

Uses trained context from uploaded PDFs

ğŸ™ï¸ Voice Assistant

Whisper converts speech â†’ text

Supports Telugu speech recognition

AI replies back using selected LLM

ğŸ“„ PDF Training (Per Model)

You can upload PDFs and the bot learns from them:

Extracts text

Saves corpus per model

Used for contextual replies

ğŸ” Admin Panel

Simple login (admin/msme@123)

Upload PDFs

View training info

Delete training data

ğŸ’¬ Chat Logging

All user messages are saved per model for audit and improvement.

ğŸ› ï¸ Tech Stack
Frontend

React.js

Axios

Custom UI Components

Voice Recorder

Backend

Python Flask

Whisper (small model)

PyPDF2

Deep Translator

Ollama local models

CORS enabled

ğŸ“¦ Project Structure
project/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ llama/
â”‚   â”‚   â”œâ”€â”€ phi/
â”‚   â”‚   â””â”€â”€ mistral/
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”œâ”€â”€ build/
    â””â”€â”€ ...

âš™ï¸ Installation Guide
1ï¸âƒ£ Install Python Requirements
pip install flask flask-cors python-dotenv deep-translator PyPDF2 openai-whisper requests

2ï¸âƒ£ Install Whisper (FFmpeg Required)
pip install openai-whisper


Install FFmpeg:

Windows: download from ffmpeg.org

Linux: sudo apt install ffmpeg

Mac: brew install ffmpeg

ğŸ¤– Install Ollama & Models
Install Ollama

Download from:
https://ollama.com/download

Check if running:

ollama list

Pull required models:
ollama pull llama3.2
ollama pull phi3
ollama pull mistral

â–¶ï¸ Running the Backend

Inside the backend folder:

python app.py


Runs at:

http://localhost:5000

â–¶ï¸ Running the Frontend

Inside the frontend folder:

npm install
npm start


Runs at:

http://localhost:3000

ğŸ“¡ API Endpoints
Chat
POST /api/chat

Voice Transcription
POST /api/transcribe

Admin Login
POST /api/admin/login

Upload Training PDFs
POST /api/admin/train

Get Training Info
GET /api/admin/train/info?model=llama

Delete Model Data
POST /api/admin/train/delete?model=mistral

ğŸ§ª Troubleshooting
âŒ No response in frontend?

âœ” Ensure backend ollama_chat_response uses:

"stream": False


âœ” Check Ollama is running:

curl http://localhost:11434


âœ” Verify model exists:

ollama list

ğŸ“ License

This project is developed for MSME ONE Support Assistant.
All rights reserved.
